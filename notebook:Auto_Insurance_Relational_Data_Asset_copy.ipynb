{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "id": "69537aa1-e270-4e2c-985a-e14087e4699b"
            },
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Auto Insurance Churn Data Set"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following notebook imports data from a public GitHub account, creates pandas data frames and exports the data frames to CSV files in the project. You will need to add a project token to your notebook for it to work. Please see the link below for information on inserting a project token.\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The data asset is relational.  There are four different data files.  One represents customer information.  A second contains address information.  A third contains demographic data, and a fourth includes customer cancellation information.  All of the data sets have linking ids, either ADDRESS_ID or CUSTOMER_ID.  The ADDRESS_ID is specific to a postal service address.  The CUSTOMER_ID is unique to a particular individual.  Note that there can be multiple customers assigned to the same address.  Also, note that not all customers have a match in the demographic table. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There are 1,536,673 unique addresses.\n\nThere are 2,280,321 unique customers. Of these, 2,112,579 have demographic information, and 269,259 cancelled during the previous year.\n\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This data is synthetic.  The customer information is all fictitious.  The latitude-longitude information generally refers to the Dallas-Fort Worth Metroplex in North Texas and is mappable at a high level.  Just be aware that if you drill down too far, some people may live in the middle of Jerry World, DFW Airport, or Lake Grapevine.  Any lat/long pointing to a specific residence, business, or other physical site is purely coincidental.  The physical addresses are fake and are unrelated to the lat/long. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In the termination table, you can derive a binary (churn/did not churn) from the ACCT_SUSPD_DATE field.  The data set is modelable.  That is, you can use the other data in the data to predict who did and did not churn.  The underlying logic behind the prediction should be consistent with predicting auto insurance churn in the real world. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Table of Contents"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Insert your token here."
        },
        {
            "cell_type": "raw",
            "metadata": {},
            "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='XXXXXXXXXXX', project_access_token='XXXXXXXXXXXXXXXXX')\npc = project.project_context\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import Libraries"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "97a1e84d-47d1-4b92-b24c-7345a3415cf2"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: plotly in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (5.1.0)\nCollecting plotly\n  Downloading plotly-5.12.0-py2.py3-none-any.whl (15.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15.2 MB 10.1 MB/s eta 0:00:01B 10.1 MB/s eta 0:00:02\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 15.1 MB 10.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from plotly) (8.0.1)\nInstalling collected packages: plotly\n  Attempting uninstall: plotly\n    Found existing installation: plotly 5.1.0\n    Uninstalling plotly-5.1.0:\n      Successfully uninstalled plotly-5.1.0\nSuccessfully installed plotly-5.12.0\nCollecting chart-studio\n  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 64 kB 1.6 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: plotly in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from chart-studio) (5.12.0)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from chart-studio) (2.26.0)\nCollecting retrying>=1.3.3\n  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from chart-studio) (1.15.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from plotly->chart-studio) (8.0.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->chart-studio) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->chart-studio) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->chart-studio) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->chart-studio) (3.3)\nInstalling collected packages: retrying, chart-studio\nSuccessfully installed chart-studio-1.1.0 retrying-1.3.4\n"
                }
            ],
            "source": "\n!pip install plotly --upgrade\n!pip install chart-studio --upgrade"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "5e6bbf34-7b1e-4881-8b8a-fb434590ab97"
            },
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\n\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nimport plotly as plotly"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import Address Data Frame"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "2463424d-b64e-4c9d-9a09-db1693d2d9a4"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "rm: cannot remove 'df_add1.csv': No such file or directory\nrm: cannot remove 'df_add2.csv': No such file or directory\nrm: cannot remove 'df_add3.csv': No such file or directory\nrm: cannot remove 'df_add4.csv': No such file or directory\nrm: cannot remove 'df_add5.csv': No such file or directory\nrm: cannot remove 'df_add6.csv': No such file or directory\nrm: cannot remove 'df_add7.csv': No such file or directory\nrm: cannot remove 'df_add9.csv': No such file or directory\nrm: cannot remove 'df_add8.csv': No such file or directory\nrm: cannot remove 'df_add0.csv': No such file or directory\n--2023-01-23 16:51:54--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add1.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12311233 (12M) [text/plain]\nSaving to: \u2018df_add1.csv\u2019\n\ndf_add1.csv         100%[===================>]  11.74M  --.-KB/s    in 0.08s   \n\n2023-01-23 16:51:55 (156 MB/s) - \u2018df_add1.csv\u2019 saved [12311233/12311233]\n\n--2023-01-23 16:51:56--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add2.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12346756 (12M) [text/plain]\nSaving to: \u2018df_add2.csv\u2019\n\ndf_add2.csv         100%[===================>]  11.77M  --.-KB/s    in 0.06s   \n\n2023-01-23 16:51:56 (184 MB/s) - \u2018df_add2.csv\u2019 saved [12346756/12346756]\n\n--2023-01-23 16:51:57--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add3.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12250120 (12M) [text/plain]\nSaving to: \u2018df_add3.csv\u2019\n\ndf_add3.csv         100%[===================>]  11.68M  --.-KB/s    in 0.06s   \n\n2023-01-23 16:51:58 (190 MB/s) - \u2018df_add3.csv\u2019 saved [12250120/12250120]\n\n--2023-01-23 16:51:58--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add4.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12331495 (12M) [text/plain]\nSaving to: \u2018df_add4.csv\u2019\n\ndf_add4.csv         100%[===================>]  11.76M  --.-KB/s    in 0.07s   \n\n2023-01-23 16:51:59 (165 MB/s) - \u2018df_add4.csv\u2019 saved [12331495/12331495]\n\n--2023-01-23 16:52:00--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add5.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12357733 (12M) [text/plain]\nSaving to: \u2018df_add5.csv\u2019\n\ndf_add5.csv         100%[===================>]  11.79M  --.-KB/s    in 0.06s   \n\n2023-01-23 16:52:01 (188 MB/s) - \u2018df_add5.csv\u2019 saved [12357733/12357733]\n\n--2023-01-23 16:52:01--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add6.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12310551 (12M) [text/plain]\nSaving to: \u2018df_add6.csv\u2019\n\ndf_add6.csv         100%[===================>]  11.74M  --.-KB/s    in 0.07s   \n\n2023-01-23 16:52:02 (173 MB/s) - \u2018df_add6.csv\u2019 saved [12310551/12310551]\n\n--2023-01-23 16:52:03--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add7.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12294756 (12M) [text/plain]\nSaving to: \u2018df_add7.csv\u2019\n\ndf_add7.csv         100%[===================>]  11.72M  --.-KB/s    in 0.06s   \n\n2023-01-23 16:52:04 (210 MB/s) - \u2018df_add7.csv\u2019 saved [12294756/12294756]\n\n--2023-01-23 16:52:04--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add8.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12285652 (12M) [text/plain]\nSaving to: \u2018df_add8.csv\u2019\n\ndf_add8.csv         100%[===================>]  11.72M  --.-KB/s    in 0.07s   \n\n2023-01-23 16:52:05 (175 MB/s) - \u2018df_add8.csv\u2019 saved [12285652/12285652]\n\n--2023-01-23 16:52:06--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add9.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12345935 (12M) [text/plain]\nSaving to: \u2018df_add9.csv\u2019\n\ndf_add9.csv         100%[===================>]  11.77M  --.-KB/s    in 0.08s   \n\n2023-01-23 16:52:07 (148 MB/s) - \u2018df_add9.csv\u2019 saved [12345935/12345935]\n\n--2023-01-23 16:52:07--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add0.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12247785 (12M) [text/plain]\nSaving to: \u2018df_add0.csv\u2019\n\ndf_add0.csv         100%[===================>]  11.68M  --.-KB/s    in 0.07s   \n\n2023-01-23 16:52:08 (159 MB/s) - \u2018df_add0.csv\u2019 saved [12247785/12247785]\n\n"
                },
                {
                    "data": {
                        "text/plain": "{'file_name': 'df_address.csv',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'autoinsurancerelationaldataasset-donotdelete-pr-ciyedg6tvptzqy',\n 'asset_id': '20cd41b4-331e-4281-8f68-7e8ef1d60c17'}"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "#Remove the data if you run this notebook more than once\n!rm df_add1.csv\n!rm df_add2.csv\n!rm df_add3.csv\n!rm df_add4.csv\n!rm df_add5.csv\n!rm df_add6.csv\n!rm df_add7.csv\n!rm df_add9.csv\n!rm df_add8.csv\n!rm df_add0.csv\n#import from github\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add1.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add2.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add3.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add4.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add5.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add6.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add7.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add8.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add9.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_add0.csv\n# Convert csv to pandas dataframe\ndf_add1 = pd.read_csv(\"df_add1.csv\", sep=\",\", header=0)\ndf_add2 = pd.read_csv(\"df_add2.csv\", sep=\",\", header=0)\ndf_add3 = pd.read_csv(\"df_add3.csv\", sep=\",\", header=0)\ndf_add4 = pd.read_csv(\"df_add4.csv\", sep=\",\", header=0)\ndf_add5 = pd.read_csv(\"df_add5.csv\", sep=\",\", header=0)\ndf_add6 = pd.read_csv(\"df_add6.csv\", sep=\",\", header=0)\ndf_add7 = pd.read_csv(\"df_add7.csv\", sep=\",\", header=0)\ndf_add8 = pd.read_csv(\"df_add8.csv\", sep=\",\", header=0)\ndf_add9 = pd.read_csv(\"df_add9.csv\", sep=\",\", header=0)\ndf_add0 = pd.read_csv(\"df_add0.csv\", sep=\",\", header=0)\n\n# append the pandas dataframes\ndf_address = pd.concat([df_add1,df_add2,df_add3,df_add4,df_add5,df_add6,df_add7,df_add8,df_add9,df_add0], ignore_index=True).drop_duplicates()\n# save the data frame as a csv in the project\nfrom project_lib import Project\n\nproject.save_data(file_name = \"df_address.csv\",data = df_address.to_csv(index=False),overwrite=True)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "7a74838b-276f-442d-813f-a8028825a897"
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ADDRESS_ID</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>STREET_ADDRESS</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.213011e+11</td>\n      <td>32.315803</td>\n      <td>-96.627896</td>\n      <td>8457 Wright Mountains Apt. 377</td>\n      <td>Ennis</td>\n      <td>TX</td>\n      <td>Ellis</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.213000e+11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>082 Cline Mountains Apt. 353</td>\n      <td>Irving</td>\n      <td>TX</td>\n      <td>Dallas</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.213002e+11</td>\n      <td>32.806290</td>\n      <td>-96.779857</td>\n      <td>457 John Mills</td>\n      <td>Dallas</td>\n      <td>TX</td>\n      <td>Dallas</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.213013e+11</td>\n      <td>32.825737</td>\n      <td>-96.939687</td>\n      <td>5726 Barnett Meadow</td>\n      <td>Irving</td>\n      <td>TX</td>\n      <td>Dallas</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.213010e+11</td>\n      <td>32.867192</td>\n      <td>-96.715552</td>\n      <td>050 Nicholas Views</td>\n      <td>Dallas</td>\n      <td>TX</td>\n      <td>Dallas</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "     ADDRESS_ID   LATITUDE  LONGITUDE                  STREET_ADDRESS    CITY  \\\n0  5.213011e+11  32.315803 -96.627896  8457 Wright Mountains Apt. 377   Ennis   \n1  5.213000e+11        NaN        NaN    082 Cline Mountains Apt. 353  Irving   \n2  5.213002e+11  32.806290 -96.779857                  457 John Mills  Dallas   \n3  5.213013e+11  32.825737 -96.939687             5726 Barnett Meadow  Irving   \n4  5.213010e+11  32.867192 -96.715552              050 Nicholas Views  Dallas   \n\n  STATE  COUNTY  \n0    TX   Ellis  \n1    TX  Dallas  \n2    TX  Dallas  \n3    TX  Dallas  \n4    TX  Dallas  "
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_address.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "6d683763-8a79-46f9-ab19-4df937d75b99"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "(1536673, 7)"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_address.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Column Descriptions"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "ADDRESS_ID -- Unique ID for a specific address\n\nZIP5 -- Five Digit US Postal Service Zip Code\n\nLATITUDE -- Lattitude of the address\n\nLONGITUDE -- Longitude of the address\n\nSTREET_ADDRESS -- Mailing Address of the address\n\nCITY -- City\n\nSTATE -- State\n\nCOUNTY -- County"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import Customer Data Frame"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "4c745558-0d45-43f9-98cd-70bd9a4fd10c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "rm: cannot remove 'df_cust1.csv': No such file or directory\nrm: cannot remove 'df_cust2.csv': No such file or directory\nrm: cannot remove 'df_cust3.csv': No such file or directory\nrm: cannot remove 'df_cust4.csv': No such file or directory\nrm: cannot remove 'df_cust5.csv': No such file or directory\nrm: cannot remove 'df_cust6.csv': No such file or directory\nrm: cannot remove 'df_cust7.csv': No such file or directory\nrm: cannot remove 'df_cust9.csv': No such file or directory\nrm: cannot remove 'df_cust8.csv': No such file or directory\nrm: cannot remove 'df_cust0.csv': No such file or directory\n--2023-01-23 16:52:33--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust1.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20197229 (19M) [text/plain]\nSaving to: \u2018df_cust1.csv\u2019\n\ndf_cust1.csv        100%[===================>]  19.26M  --.-KB/s    in 0.09s   \n\n2023-01-23 16:52:33 (205 MB/s) - \u2018df_cust1.csv\u2019 saved [20197229/20197229]\n\n--2023-01-23 16:52:34--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust2.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20199518 (19M) [text/plain]\nSaving to: \u2018df_cust2.csv\u2019\n\ndf_cust2.csv        100%[===================>]  19.26M  --.-KB/s    in 0.1s    \n\n2023-01-23 16:52:35 (180 MB/s) - \u2018df_cust2.csv\u2019 saved [20199518/20199518]\n\n--2023-01-23 16:52:36--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust3.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20181032 (19M) [text/plain]\nSaving to: \u2018df_cust3.csv\u2019\n\ndf_cust3.csv        100%[===================>]  19.25M  --.-KB/s    in 0.09s   \n\n2023-01-23 16:52:36 (217 MB/s) - \u2018df_cust3.csv\u2019 saved [20181032/20181032]\n\n--2023-01-23 16:52:37--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust4.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20099325 (19M) [text/plain]\nSaving to: \u2018df_cust4.csv\u2019\n\ndf_cust4.csv        100%[===================>]  19.17M  --.-KB/s    in 0.09s   \n\n2023-01-23 16:52:38 (216 MB/s) - \u2018df_cust4.csv\u2019 saved [20099325/20099325]\n\n--2023-01-23 16:52:39--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust5.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20198766 (19M) [text/plain]\nSaving to: \u2018df_cust5.csv\u2019\n\ndf_cust5.csv        100%[===================>]  19.26M  --.-KB/s    in 0.1s    \n\n2023-01-23 16:52:40 (177 MB/s) - \u2018df_cust5.csv\u2019 saved [20198766/20198766]\n\n--2023-01-23 16:52:40--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust6.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20110329 (19M) [text/plain]\nSaving to: \u2018df_cust6.csv\u2019\n\ndf_cust6.csv        100%[===================>]  19.18M  --.-KB/s    in 0.1s    \n\n2023-01-23 16:52:41 (197 MB/s) - \u2018df_cust6.csv\u2019 saved [20110329/20110329]\n\n--2023-01-23 16:52:42--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust7.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20188702 (19M) [text/plain]\nSaving to: \u2018df_cust7.csv\u2019\n\ndf_cust7.csv        100%[===================>]  19.25M  --.-KB/s    in 0.09s   \n\n2023-01-23 16:52:43 (220 MB/s) - \u2018df_cust7.csv\u2019 saved [20188702/20188702]\n\n--2023-01-23 16:52:43--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust8.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20192263 (19M) [text/plain]\nSaving to: \u2018df_cust8.csv\u2019\n\ndf_cust8.csv        100%[===================>]  19.26M  --.-KB/s    in 0.1s    \n\n2023-01-23 16:52:44 (190 MB/s) - \u2018df_cust8.csv\u2019 saved [20192263/20192263]\n\n--2023-01-23 16:52:45--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust9.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20202666 (19M) [text/plain]\nSaving to: \u2018df_cust9.csv\u2019\n\ndf_cust9.csv        100%[===================>]  19.27M  --.-KB/s    in 0.08s   \n\n2023-01-23 16:52:46 (230 MB/s) - \u2018df_cust9.csv\u2019 saved [20202666/20202666]\n\n--2023-01-23 16:52:46--  https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust0.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20216231 (19M) [text/plain]\nSaving to: \u2018df_cust0.csv\u2019\n\ndf_cust0.csv        100%[===================>]  19.28M  --.-KB/s    in 0.1s    \n\n2023-01-23 16:52:47 (178 MB/s) - \u2018df_cust0.csv\u2019 saved [20216231/20216231]\n\n"
                }
            ],
            "source": "#Remove the data if you run this notebook more than once\n!rm df_cust1.csv\n!rm df_cust2.csv\n!rm df_cust3.csv\n!rm df_cust4.csv\n!rm df_cust5.csv\n!rm df_cust6.csv\n!rm df_cust7.csv\n!rm df_cust9.csv\n!rm df_cust8.csv\n!rm df_cust0.csv\n#import from github\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust1.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust2.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust3.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust4.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust5.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust6.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust7.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust8.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust9.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_cust0.csv\n# Convert csv to pandas dataframe\ndf_cust1 = pd.read_csv(\"df_cust1.csv\", sep=\",\", header=0)\ndf_cust2 = pd.read_csv(\"df_cust2.csv\", sep=\",\", header=0)\ndf_cust3 = pd.read_csv(\"df_cust3.csv\", sep=\",\", header=0)\ndf_cust4 = pd.read_csv(\"df_cust4.csv\", sep=\",\", header=0)\ndf_cust5 = pd.read_csv(\"df_cust5.csv\", sep=\",\", header=0)\ndf_cust6 = pd.read_csv(\"df_cust6.csv\", sep=\",\", header=0)\ndf_cust7 = pd.read_csv(\"df_cust7.csv\", sep=\",\", header=0)\ndf_cust8 = pd.read_csv(\"df_cust8.csv\", sep=\",\", header=0)\ndf_cust9 = pd.read_csv(\"df_cust9.csv\", sep=\",\", header=0)\ndf_cust0 = pd.read_csv(\"df_cust0.csv\", sep=\",\", header=0)\n\n# append the pandas dataframes\ndf_customer = pd.concat([df_cust1,df_cust2,df_cust3,df_cust4,df_cust5,df_cust6,df_cust7,df_cust8,df_cust9,df_cust0], ignore_index=True).drop_duplicates()\n# save the data frame as a csv in the project\nfrom project_lib import Project\n\nproject.save_data(file_name = \"df_customer.csv\",data = df_customer.to_csv(index=False),overwrite=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "058248f8-1758-49f3-a56d-9d3250e4f0fa"
            },
            "outputs": [],
            "source": "df_customer.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "1c2e5c7d-3e5c-43f0-aca5-231e37e8fdf0"
            },
            "outputs": [],
            "source": "df_customer.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Column Descriptions"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "INDIVIDUAL_ID -- Unique ID for a specific insurance customer\n\nADDRESS_ID -- Unique ID for the primary address associated with a customer\n\nCURR_ANN_AMT -- The Annual dollar value paid by the customer.  It is not the policy amount.  It is actually amount the customer paid during the previous year.\n\nDAYS_TENURE -- The time in days individual has been a customer with the insurance agency.\n\nCUST_ORIG_DATE -- The data the individual became a customer\n\nAGE_IN_YEARS -- Age of the individual.\n\nDATE_OF_BIRTH -- Individual's date of birth\n\nSOCIAL_SECURITY_NUMBER -- Social Security Number.  Note the middle two digts are XX to prevent any coincidental actuall SSNs from appearing.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import Demographic Data Frame"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3a84da27-c48c-45f7-bd26-c9553b5a283f"
            },
            "outputs": [],
            "source": "#Remove the data if you run this notebook more than once\n!rm df_demo1.csv\n!rm df_demo2.csv\n!rm df_demo3.csv\n!rm df_demo4.csv\n!rm df_demo5.csv\n!rm df_demo6.csv\n!rm df_demo7.csv\n!rm df_demo8.csv\n!rm df_demo9.csv\n!rm df_demo0.csv\n#import first half from github\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo1.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo2.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo3.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo4.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo5.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo6.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo7.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo8.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo9.csv\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_demo0.csv   \n\n# Convert csv to pandas dataframe\ndf_demo1 = pd.read_csv(\"df_demo1.csv\", sep=\",\", header=0)\ndf_demo2 = pd.read_csv(\"df_demo2.csv\", sep=\",\", header=0)\ndf_demo3 = pd.read_csv(\"df_demo3.csv\", sep=\",\", header=0)\ndf_demo4 = pd.read_csv(\"df_demo4.csv\", sep=\",\", header=0)\ndf_demo5 = pd.read_csv(\"df_demo5.csv\", sep=\",\", header=0)\ndf_demo6 = pd.read_csv(\"df_demo6.csv\", sep=\",\", header=0)\ndf_demo7 = pd.read_csv(\"df_demo7.csv\", sep=\",\", header=0)\ndf_demo8 = pd.read_csv(\"df_demo8.csv\", sep=\",\", header=0)\ndf_demo9 = pd.read_csv(\"df_demo9.csv\", sep=\",\", header=0)\ndf_demo0 = pd.read_csv(\"df_demo0.csv\", sep=\",\", header=0)\n\n\ndf_demographic = pd.concat([df_demo1,df_demo2,df_demo3,df_demo4,df_demo5,df_demo6,df_demo0,df_demo7,df_demo8,df_demo9], ignore_index=True).drop_duplicates()\n\nfrom project_lib import Project\n\nproject.save_data(file_name = \"df_demographic.csv\",data = df_demographic.to_csv(index=False),overwrite=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "69259523-9851-4967-90d2-0f69e0ef7440"
            },
            "outputs": [],
            "source": "df_demographic.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Column Descriptions"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "INDIVIDUAL_ID -- Unique ID for a specific insurance customer\n\nINCOME -- Estimated Income for the Household associated with the individual\n\nHAS_CHILDREN -- Flag, 1 indicates the individual has children in the home, 0 otherwise.\n\nLENGTH_OF_RESIDENCE -- Estimated number of years the individual has lived in their current home.\n\nMARITAL_STATUS -- Estimated marital status.  Married or Single.\n\nHOME_MARKET_VALUE -- Estimate value of home.\n\nHOME_OWNER -- Flag, 1 individual owns primary home, 0 otherwise.\n\nCOLLEGE_DEGREE -- Flag, 1 individual has a college degree or more, 0 otherwise.\n\nGOOD_CREDIT -- Flag, 1 individual has FICO greater than 630, 0 otherwise."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "8a761d3b-4e4c-4501-a0f8-1defa7bbd0eb"
            },
            "outputs": [],
            "source": "df_demographic.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import Customer Termination Data Frame"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "4f9685c1-d97c-47a5-8c1e-7d24fc6390f3"
            },
            "outputs": [],
            "source": "#Remove the data if you run this notebook more than once\n!rm df_term.csv\n\n#import first half from github\n!wget https://raw.githubusercontent.com/shadgriffin/auto-insrance-churn-data/main/df_term.csv\n\n# Convert csv to pandas dataframe\ndf_termination = pd.read_csv(\"df_term.csv\", sep=\",\", header=0)\n\n\n\ndf_termination = df_termination.drop_duplicates()\n\nfrom project_lib import Project\n\nproject.save_data(file_name = \"df_termination.csv\",data = df_termination.to_csv(index=False),overwrite=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "824398d7-73df-4f9b-9a82-9aae925f9045"
            },
            "outputs": [],
            "source": "df_termination.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Column Descriptions"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "INDIVIDUAL_ID -- Unique ID for a specific insurance customer\n\nACCT_SUSPD_DATE -- Day of Account Suspension or Cancellation"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The termination data frame has 269,259 records"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "7fbe0b42-bc4a-46b3-acbd-d6ce0ac62d8f"
            },
            "outputs": [],
            "source": "df_termination.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Create a churn to tenure chart."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To show the robustness of the data, I will create a simple chart showing the relationship between tenure and churn."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "0fecffa9-6549-44a0-951f-8b53157d5368"
            },
            "outputs": [],
            "source": "df=pd.merge(df_customer, df_termination, on = \"INDIVIDUAL_ID\", how = \"left\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "620d1621-2c3a-45e2-a393-c134024fdbdf"
            },
            "outputs": [],
            "source": "df['CHURN'] = np.where(df.ACCT_SUSPD_DATE.isnull(), 0, 1)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "478e974f-710e-4d9a-b1e3-ee4e3c570f91"
            },
            "outputs": [],
            "source": "df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "9aa20814-ca17-4204-802e-2094887e3774"
            },
            "outputs": [],
            "source": "df['VARIABLE']=df['DAYS_TENURE']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "018450c2-6497-4351-b65c-6fe3368ca421"
            },
            "outputs": [],
            "source": "dfx=df\n#Sort the data by ID and Date\ndfx=dfx.sort_values(by=['VARIABLE'], ascending=[True])\n#add a very small random number to break ties\ndfx['wookie'] = (np.random.randint(0, 100, dfx.shape[0]))/1000000000000\ndfx['VARIABLE']=dfx['VARIABLE']+dfx['wookie']\n#Create percentiles based on Tenure\ndfx['PTILE'] = pd.qcut(dfx['VARIABLE'], 100, labels=np.arange(100, 0, -1))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6586fef2-bf36-4db9-87b0-fb948d45f159"
            },
            "outputs": [],
            "source": "dfx.head(100)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "0faeb7f0-8226-4bc1-81ac-0d75621bfbcc"
            },
            "outputs": [],
            "source": "# Find the minimum probability for each PTILE\n\ntips_summedx = pd.DataFrame(dfx.groupby(['PTILE'])['VARIABLE'].mean())\n#Sum the number of Failures in each PTILE.\ntips_summedy = pd.DataFrame(dfx.groupby(['PTILE'])['VARIABLE'].sum())\n# count the records in each PTILE\ntips_summedz = pd.DataFrame(dfx.groupby(['PTILE'])['VARIABLE'].count())\n#Aggregate the summaries into one dataframe\n\ntips_summedw = pd.DataFrame(dfx.groupby(['PTILE'])['CHURN'].mean())\n#Sum the number of Failures in each PTILE.\ntips = pd.concat([tips_summedx, tips_summedy,tips_summedz,tips_summedw], axis=1)\ntips.columns = ['VARIABLE','CANCELS', 'OBS','CHURN_RATE']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "c299612e-3af4-4c22-84fd-14d0ecc81c90"
            },
            "outputs": [],
            "source": "tips.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3fbe82ce-eceb-40f6-8d5e-34909cd10cf3"
            },
            "outputs": [],
            "source": "x1 = tips['VARIABLE']\ny1 = tips['CHURN_RATE']\n\ntrace = go.Scatter(\n    x = x1,\n    y = y1,\n    name='Churn versus Tenure')\n\nlayout = go.Layout(\n    title='Churn by Tenure',\n    xaxis=dict(\n        title='Tenure',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='Churn Rate',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    showlegend=True,\n)\n    \ndata=[trace]  \nfig = go.Figure(data=data, layout=layout)\n#plot_url = py.plot(fig, filename='styling-names')\nplotly.offline.iplot(fig, filename='shapes-lines')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Note the high churn rate at six months.  This stems from customers paying up-front for a six-month policy to get coverage for a state-issued auto inspection and the high turnover of people who leave after their first policy contract.  Many consumers churn after 12 months as well.  All new customers agree to a six or twelve-month agreement.  After the first 12 months, the churn rate stabilizes."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3ea1b377-d6d3-4b33-9779-cd7d2d8ed259"
            },
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.11",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}